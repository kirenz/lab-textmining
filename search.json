[
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Download the Jupyter Notebooks in your local folder textmining.\n\nTask 1: Textmining\nTask 2: Sentiment analyis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome üëã",
    "section": "",
    "text": "Welcome to the lab ‚Äú‚Äú\n\nIn this lab you will ‚Ä¶\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you meet all the requirements and have read the lecture slides before you start with the assignments\n\n\nWhat you will learn in this lab:\n\nHow to set up a MySQL database\nUse SQL for data analysis\nMake use of Pandas for data analysis in Python\nUse Altair for data visualization in Python"
  },
  {
    "objectID": "slides/slides.html#text",
    "href": "slides/slides.html#text",
    "title": "foo",
    "section": "Text",
    "text": "Text\n\na ü§ñ\n\nabc\n\n\n\n\nb\nc1\n\nüìö Required reading: A & B (2023)\nhttps://arxiv.org/pdf/2303.12712.pdf\n\nRussell & Norvig, 2009"
  },
  {
    "objectID": "slides/slides.html#image",
    "href": "slides/slides.html#image",
    "title": "foo",
    "section": "Image",
    "text": "Image"
  },
  {
    "objectID": "slides/slides.html#video",
    "href": "slides/slides.html#video",
    "title": "foo",
    "section": "Video",
    "text": "Video"
  },
  {
    "objectID": "slides/slides.html#a-lot-of-text",
    "href": "slides/slides.html#a-lot-of-text",
    "title": "foo",
    "section": "A lot of text",
    "text": "A lot of text\nSmaller heading"
  },
  {
    "objectID": "slides/slides.html#background-image",
    "href": "slides/slides.html#background-image",
    "title": "foo",
    "section": "Background image",
    "text": "Background image\nabc"
  },
  {
    "objectID": "slides/slides.html#code",
    "href": "slides/slides.html#code",
    "title": "foo",
    "section": "Code",
    "text": "Code\n1print('Hello World')\n2for i in LIST:\n  df[i] = df[i].astype('cat')\n\n1\n\nPrint Hello World, and then,\n\n2\n\ntransform all columns in the LIST element to categorical variables"
  },
  {
    "objectID": "code/1_textmining.html",
    "href": "code/1_textmining.html",
    "title": "Text Mining with NLTK",
    "section": "",
    "text": "We need the following modules in this notebook:\n\nnltk\nwordcloud\npandas\naltair\n\n\n# we suppress some unimportant warnings\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)"
  },
  {
    "objectID": "code/1_textmining.html#python-setup",
    "href": "code/1_textmining.html#python-setup",
    "title": "Text Mining with NLTK",
    "section": "",
    "text": "We need the following modules in this notebook:\n\nnltk\nwordcloud\npandas\naltair\n\n\n# we suppress some unimportant warnings\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)"
  },
  {
    "objectID": "code/1_textmining.html#data",
    "href": "code/1_textmining.html#data",
    "title": "Text Mining with NLTK",
    "section": "Data",
    "text": "Data\n\nData import\n\nimport pandas as pd\n\n# Import some Tweets\ndf = pd.read_csv(\"https://raw.githubusercontent.com/kirenz/datasets/master/tweets-cnn.csv\")\n\n# drop some columns\ndf.drop(columns=[\"author_id\", \"edit_history_tweet_ids\", \"id\"], inplace=True)\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntext\ncreated_at\n\n\n\n\n0\nThe body of missing Princeton University stude...\n2022-10-20T19:58:17.000Z\n\n\n1\nUK Prime Minister Liz Truss quits after a disa...\n2022-10-20T12:37:10.000Z\n\n\n2\nTrump weighs letting federal agents return to ...\n2022-10-19T23:03:37.000Z\n\n\n\n\n\n\n\n\n\nData corrections\n\ndf['text'] = df['text'].astype(str).str.lower()\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntext\ncreated_at\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20T19:58:17.000Z\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20T12:37:10.000Z\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19T23:03:37.000Z\n\n\n\n\n\n\n\n\ndf['created_at'] = pd.to_datetime(df['created_at'])\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 22 entries, 0 to 21\nData columns (total 2 columns):\n #   Column      Non-Null Count  Dtype              \n---  ------      --------------  -----              \n 0   text        22 non-null     object             \n 1   created_at  22 non-null     datetime64[ns, UTC]\ndtypes: datetime64[ns, UTC](1), object(1)\nmemory usage: 480.0+ bytes"
  },
  {
    "objectID": "code/1_textmining.html#text-mining-data-preparation",
    "href": "code/1_textmining.html#text-mining-data-preparation",
    "title": "Text Mining with NLTK",
    "section": "Text mining data preparation",
    "text": "Text mining data preparation\n\nTokenization\n\nWe use NLTK‚Äôs RegexpTokenizer to perform tokenization in combination with regular expressions.\nTo learn more about regular expressions (‚Äúregexp‚Äù), visit the following sites:\nregular expression basics.\ninteractive regular expressions tool\n\\w+ matches Unicode word characters with one or more occurrences;\nthis includes most characters that can be part of a word in any language, as well as numbers and the underscore.\n\n\nfrom nltk.tokenize import RegexpTokenizer\n\nHint\n\n\nregexp = RegexpTokenizer('___') # use regular expression to match (multiple) word characters and numbers\n\ndf['text_token']=df['___'].apply(___.tokenize) # insert the data column and the regular expression pattern\n\n\n### BEGIN SOLUTION\nregexp = RegexpTokenizer('\\w+')\n\ndf['text_token']=df['text'].apply(regexp.tokenize)\n### END SOLUTION\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n[the, body, of, missing, princeton, university...\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n[uk, prime, minister, liz, truss, quits, after...\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n[trump, weighs, letting, federal, agents, retu...\n\n\n3\nbritain's home secretary suella braverman quit...\n2022-10-19 16:17:29+00:00\n[britain, s, home, secretary, suella, braverma...\n\n\n4\nrussian president vladimir putin signs a decre...\n2022-10-19 12:02:15+00:00\n[russian, president, vladimir, putin, signs, a...\n\n\n\n\n\n\n\n\n# Check your code\nassert df.iloc[0, 2] == ['the',\n 'body',\n 'of',\n 'missing',\n 'princeton',\n 'university',\n 'student',\n 'misrach',\n 'ewunetie',\n 'has',\n 'been',\n 'found',\n 'https',\n 't',\n 'co',\n '66wv0od5ut']\n\nCompare the entries of text with text_token. Do you notice any differences?\n\n\nStopwords\n\nStop words are words in a stop list which are dropped before analysing natural language data since they don‚Äôt contain valuable information (like ‚Äúwill‚Äù, ‚Äúand‚Äù, ‚Äúor‚Äù, ‚Äúhas‚Äù, ‚Ä¶).\n\n\nimport nltk\n\n# download the stopwords package\nnltk.download('stopwords')\n\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/jankirenz/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\nTrue\n\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\n\n# Make a list of english stopwords\nstopwords = nltk.corpus.stopwords.words(\"english\")\n\n\n# make your own custom stopwords\nmy_stopwords = ['https', 'co']\n\n\n# Extend the stopword list with your own custom stopwords\nstopwords.extend(my_stopwords)\n\n\nNext, we use a lambda function (anonymous function) to remove the stopwords:\n\nHint:\nWe want to get rid of all stopwords in text_token and create a new column called text_token_s (for ‚Äútext token without stopwords‚Äù).\nTherefore, we use the following code:\n\ndf['text_token_s'] = df['text_token'].___(___ x: [__ for __ in x if __ not in ___])\n\nYou need to complete the code with the follwing information:\n\n.apply applies a function along the rows of the DataFrame.\nlambda x: is an anonymous funtion (we dont have to give it a name)\nuse i as iterator to iterate through every row and only keep words if they are not in stopwords.\n\n\n# BEGIN SOLUTION\ndf['text_token_s'] = df['text_token'].apply(lambda x: [i for i in x if i not in stopwords])\n# END SOLUTION\n\n\n# Check your code\nassert df.iloc[1,3] == ['uk',\n 'prime',\n 'minister',\n 'liz',\n 'truss',\n 'quits',\n 'disastrous',\n 'six',\n 'weeks',\n 'office',\n 'putting',\n 'course',\n 'britain',\n 'shortest',\n 'serving',\n 'leader',\n '0o0xqscrxi']\n\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\ntext_token_s\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n[the, body, of, missing, princeton, university...\n[body, missing, princeton, university, student...\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n[uk, prime, minister, liz, truss, quits, after...\n[uk, prime, minister, liz, truss, quits, disas...\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n[trump, weighs, letting, federal, agents, retu...\n[trump, weighs, letting, federal, agents, retu...\n\n\n\n\n\n\n\nCompare the entries of text_token_s with text_token. Do you notice any differences?\n\n\nTransform data and remove infrequent words\nIn the next step, we will:\n\ntransform the text tokens to a simple string (i.e.¬†from cell value [a , b , c] to ‚Äòa b c‚Äô) because the following steps (like lemmatization) can‚Äôt handle tokens\nremove words which occur less then two times (because such infrequent words usually don‚Äôt have much value for our analysis)\nsave the result in a new column called text_si (s stands for stopword and i for infrequent words)\n\nHint:\n\n___ = df['___'].___(lambda x: ' '.join([__ for __ in __ if len(__)&gt;__]))\n\n\nname the new column text_si\nuse the column text_token_s\nuse .apply to apply a lambda function to every row of the dataframe\nThe lambda function should:\n\ncombine (use join()) all word tokens (use i as an iterator) from a row in a single string (use a white space ' ' as seperator between the tokens)\nonly keep tokens which occur more than 2 times\n\n\n\n### BEGIN SOLUTION\ndf['text_si'] = df['text_token_s'].apply(lambda x: ' '.join([i for i in x if len(i)&gt;2]))\n### END SOLUTION\n\n\n# check you code\nassert df.iloc[1, 4] == 'prime minister liz truss quits disastrous six weeks office putting course britain shortest serving leader 0o0xqscrxi'\n\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\ntext_token_s\ntext_si\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n[the, body, of, missing, princeton, university...\n[body, missing, princeton, university, student...\nbody missing princeton university student misr...\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n[uk, prime, minister, liz, truss, quits, after...\n[uk, prime, minister, liz, truss, quits, disas...\nprime minister liz truss quits disastrous six ...\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n[trump, weighs, letting, federal, agents, retu...\n[trump, weighs, letting, federal, agents, retu...\ntrump weighs letting federal agents return mar...\n\n\n\n\n\n\n\nNote that this operation changes the format of your cell entries (notice the missing brackets). Do you notice further differences?\n\n\nLemmatization\n\nNext, we perform lemmatization (lemmatization is the process of converting a word to its base form).\n\n\n# we need to download some packages\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/jankirenz/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to\n[nltk_data]     /Users/jankirenz/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n\n\nTrue\n\n\n\nfrom nltk.stem import WordNetLemmatizer\n\n\n# create an object called wordnet_lem of the WordNetLemmatizer() function.\nwordnet_lem = WordNetLemmatizer()\n\n\n# create a new column called text_sil (l for lemmatization) and apply the function .lemmatize\ndf['text_sil'] = df['text_si'].apply(wordnet_lem.lemmatize)\n\n\n# we check wether there are any differences in the two columns\ncheck_difference = (df['text_sil'] == df['text_si'])\n\n# sum all True and False values\ncheck_difference.value_counts()\n\nTrue    22\ndtype: int64\n\n\nWe can observe that on our data, the lemmatization function did not change an of the words (we have only True values, which means that every row in df['text_sil'] == df['text_si']).\n\ndf.to_csv(\"sentiment-cnn.csv\", index=None)"
  },
  {
    "objectID": "code/1_textmining.html#data-visualization",
    "href": "code/1_textmining.html#data-visualization",
    "title": "Text Mining with NLTK",
    "section": "Data visualization",
    "text": "Data visualization\n\nWord cloud\nWe use a word cloud to visualize our data (word cloud example gallery)\n\n# combine all words in one object called all_words\nall_words = ' '.join([i for i in df['text_sil']])\n\n\nall_words\n\n'body missing princeton university student misrach ewunetie found 66wv0od5ut prime minister liz truss quits disastrous six weeks office putting course britain shortest serving leader 0o0xqscrxi trump weighs letting federal agents return mar lago potentially supervised search government seeks ensure docs returned ppjifj2qqq britain home secretary suella braverman quits throwing government embattled prime minister liz truss turmoil xizzmajsao russian president vladimir putin signs decree introducing martial law four ukrainian regions moscow recently claimed annexed i4d4skhrge rising food housing costs drove inflation back year high september rzcvzuvhap jury finds paul flores guilty first degree murder death kristin smart father found guilty accessory murder kiypga2ytv russian expat main source infamous trump dossier acquitted lying fbi embarrassing defeat special counsel durham vu0cacf8zn pilot passenger dead plane crashed car dealership lot near marietta ohio authorities say one ground injured xoyydu8lb6 ukraine president zelensky says country power stations destroyed russia latest round attacks dy8rz68qm8 president biden announces formal launch student loan forgiveness application website qw0k3trl4b russian fighter jet crashed residential building taking military airfield state media reports reczia3ix3 former president donald trump company charged secret service much 185 per night properties despite claims stay free cost house panel says v69rtpyzsq steve bannon sentencing recommendation seeks six months prison plus 200 000 fines contempt congress conviction qq4l6vlou5 blasts heard ukrainian capital result apparent russian missile strikes monday morning follow live updates h0p9xux3wk authorities central california arrested man connection series killings claimed lives six people nlzrnsmb11 bruce sutter young award winning relief pitcher world series champion pioneered split finger fastball died rdnsvno63v judge throws one five charges igor danchenko main source trump russia dossier major setback special counsel durham probe rhtcheq0ei robbie coltrane actor brought life lovable gamekeeper hagrid harry potter film franchise died friday according agent prw2bt21ry cavfrexhri former president trump said whether comply subpoena house select committee investigating january 2021 capitol hill insurrection 0ynzmnguuw kwasi kwarteng fired britain chancellor weeks job senior source inside downing street confirmed cnn follow live updates 4ec7sm1ctv kroger announces merging albertsons billion deal creating one largest grocery store chains s3fzgtffic'\n\n\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(width=600, \n                     height=400, \n                     random_state=2, \n                     max_font_size=100).generate(all_words)\n\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show;\n\n\n\n\n\nDifferent style:\n\n\nimport numpy as np\n\nx, y = np.ogrid[:300, :300]\nmask = (x - 150) ** 2 + (y - 150) ** 2 &gt; 130 ** 2\nmask = 255 * mask.astype(int)\n\nwc = WordCloud(background_color=\"white\", repeat=True, mask=mask)\nwc.generate(all_words)\n\nplt.axis(\"off\")\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.show;\n\n\n\n\n\n\nFrequency distributions\n\n# download the package\nnltk.download('punkt')\n\n[nltk_data] Downloading package punkt to /Users/jankirenz/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n\n\nTrue\n\n\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\n\n\n# tokenize the words\nwords_tokens = nltk.word_tokenize(all_words)\n\n\n# use the function FreqDist and save the result as fd\nfd = FreqDist(words_tokens)\n\n\nwords\n\n['albi_sidearms',\n 'maybe',\n 'jack',\n 'ueyr6nawap',\n 'sawyermerritt',\n 'sawyermerritt',\n 'tesla',\n 'china',\n 'done',\n 'amazing',\n 'work',\n 'mrbeast',\n 'planet4589',\n 'earth',\n 'called',\n 'water',\n 'samifouad',\n 'tobyliiiiiiiiii',\n 'noobtoob',\n 'thinking',\n 'quitting',\n 'jobs',\n 'amp',\n 'becoming',\n 'influencer',\n 'full',\n 'time',\n 'wdyt',\n 'zrz1eflywy',\n 'teslaownerssv',\n 'billym2k',\n 'thecryptocpa',\n 'ballaerospace',\n 'nasa_marshall',\n 'nasa',\n 'spacex',\n 'congrats',\n '_rykllan',\n 'spacex',\n 'felixschlang',\n 'marcushouse',\n 'erdayastronaut',\n 'bluemoondance74',\n 'nexthorizonssf',\n 'rocket',\n 'fleets',\n 'grows',\n 'squawkcnbc',\n 'gordonjohnson19',\n 'rainmaker1973',\n 'amazing',\n 'engine',\n 'cnunezimages',\n 'spacex',\n 'spaceintellige3',\n 'rainmaker1973',\n 'shanghai',\n 'beautiful',\n 'ppathole',\n 'probably',\n 'way',\n 'sooner',\n 'hot',\n 'civilization',\n 'unless',\n 'susceptible',\n 'extreme',\n 'natural',\n 'disasters',\n 'nuclear',\n 'power',\n 'plants',\n 'shut',\n 'watcherguru',\n 'taxing',\n 'billionaires',\n '100',\n 'drops',\n 'national',\n 'debt',\n 'one',\n 'year',\n 'deficit',\n 'spending',\n 'watcherguru',\n 'scary',\n 'something',\n 'got',\n 'give',\n 'nothing',\n 'permanent',\n 'temporary',\n 'government',\n 'program',\n 'traderjourney',\n 'exactly',\n 'lot',\n 'accounting',\n 'trickery',\n 'bill',\n 'disclosed',\n 'public',\n 'temporary',\n 'provisions',\n 'build',\n 'back',\n 'better',\n 'act',\n 'become',\n 'permanent',\n 'national',\n 'debt',\n 'increase',\n 'kkdpc45job',\n 'engineers_feed',\n 'judith',\n 'cohen',\n 'jack',\n 'black',\n 'mother',\n 'also',\n 'important',\n 'work',\n 'apollo',\n 'jborez8llw',\n '28delayslater',\n 'jvsalwjfcj',\n '28delayslater',\n 'ej9swabcfm',\n '28delayslater',\n 'mo4bi8mnqt',\n '28delayslater',\n 'fjaw6l5ba0',\n 'waitbutwhy',\n 'brain',\n 'transplants',\n 'jessica_kirsh',\n 'spacex',\n 'booster',\n 'production',\n 'currently',\n 'ahead',\n 'engine',\n 'production',\n 'tesla_raj',\n 'lot',\n 'people',\n 'realize',\n 'watch',\n 'almost',\n 'show',\n 'tesla',\n 'worldandscience',\n 'leave',\n 'hydrogen',\n 'sun',\n 'long',\n 'enough',\n 'starts',\n 'talking',\n 'rainmaker1973',\n 'wow',\n 'tobyliiiiiiiiii',\n 'rgvaerialphotos',\n 'spacex',\n 'hopefully',\n 'month',\n 'later',\n 'next',\n 'rgvaerialphotos',\n 'spacex',\n 'progress',\n 'joshdcaplan',\n 'true',\n 'billym2k',\n 'wholemarsblog',\n 'teslafsdbeta',\n 'replacing',\n 'faulty',\n 'missing',\n 'neurons',\n 'circuits',\n 'right',\n 'way',\n 'think',\n 'many',\n 'problems',\n 'solved',\n 'bridging',\n 'signals',\n 'existing',\n 'neurons',\n 'progress',\n 'accelerate',\n 'devices',\n 'humans',\n 'hard',\n 'nuanced',\n 'conversations',\n 'monkeys',\n 'next',\n 'year',\n 'newsmax',\n 'already',\n 'minimum',\n 'age',\n 'requirements',\n 'house',\n 'senate',\n 'amp',\n 'presidency',\n 'reciprocally',\n 'maximum',\n 'age',\n 'limits',\n 'stocktalkweekly',\n 'neuralink',\n 'definitely',\n 'saying',\n 'sure',\n 'increasingly',\n 'confident',\n 'possible',\n 'icannot_enough',\n 'kimpaquette',\n 'exactly',\n 'univercurious',\n 'always',\n 'blows',\n 'mind',\n 'sad',\n 'thing',\n 'back',\n 'moon',\n 'half',\n 'century',\n 'teslaownerssv',\n 'beniko26020660',\n 'coming',\n 'days',\n 'address',\n 'annoying',\n 'issues',\n 'rainmaker1973',\n 'looking',\n 'forward',\n 'visiting',\n 'heard',\n 'awesome',\n 'background',\n 'needed',\n 'exceptional',\n 'skill',\n 'software',\n 'computer',\n 'design',\n 'nasa',\n 'nasa_astronauts',\n 'congratulations',\n 'drsallyl',\n 'tesla',\n 'coming',\n 'soon',\n 'lot',\n 'cool',\n 'stuff',\n 'kimpaquette',\n 'tesla',\n 'publishes',\n 'accident',\n 'statistics',\n 'quarterly',\n 'much',\n 'better',\n 'vehicles',\n 'ridiculous',\n 'q44lsk1bnk',\n 'always',\n 'tesla',\n 'looking',\n 'hardcore',\n 'engineers',\n 'care',\n 'solving',\n 'problems',\n 'directly',\n 'affect',\n 'people',\n 'lives',\n 'major',\n 'way',\n '0b5tooohcj',\n 'aeiecon',\n 'sciguyspace',\n 'jimpethokoukis',\n 'pe_podcast_aei',\n 'good',\n 'summary',\n 'epavlic',\n 'quite',\n 'bossy',\n 'dog',\n 'billym2k',\n 'nfts',\n 'jpeging',\n 'dollar',\n 'billym2k',\n 'ercxspace',\n 'landing',\n 'tower',\n 'arms',\n 'muratpak',\n 'car',\n 'currently',\n 'orbiting',\n 'mars',\n 'muratpak',\n 'betcha',\n 'starships',\n 'mars',\n 'soon',\n 'make',\n 'real',\n 't4z5onfnww',\n 'sigzpdyx76',\n 'id_aa_carmack',\n 'haha',\n 'pretty',\n 'much',\n 'kristennetten',\n 'minimalduck',\n 'ludalisl',\n '28delayslater',\n 'johnnacrider1',\n 'arctechinc',\n 'adamhoov',\n 'sawyermerritt',\n 'garyblack00',\n 'janeidyeve',\n 'renatakonkoly',\n 'exactly',\n 'joroulette',\n 'honor',\n 'serve',\n 'nasa',\n 'countries',\n 'international',\n 'space',\n 'station',\n 'nasaspaceflight',\n '39a',\n 'hallowed',\n 'spaceflight',\n 'ground',\n 'place',\n 'deserving',\n 'starship',\n 'launch',\n 'pad',\n 'similar',\n 'improved',\n 'ground',\n 'systems',\n 'amp',\n 'tower',\n 'starbase',\n 'evafoxu',\n 'sawyermerritt',\n 'huge',\n 'cranes',\n 'cool',\n 'haha',\n 'ppathole',\n 'ercxspace',\n 'spacex',\n 'look',\n 'awesome',\n 'evafoxu',\n 'sawyermerritt',\n 'love',\n 'norway']\n\n\n\nfd\n\nFreqDist({'trump': 5, 'president': 5, 'russian': 4, 'six': 3, 'britain': 3, 'source': 3, 'one': 3, 'student': 2, 'found': 2, 'prime': 2, ...})\n\n\n\n\nMost common words\nFind the 3 most common words by using the function most_common(n=foo) (foo is a placeholder).\nUse the object fd to obtain the result\nSave the result as top_3\n\n# find the 3 most common words\n### BEGIN SOLUTION\ntop_3 = fd.most_common(n=3)\n### END SOLUTION\n\n\n# Check your code\nassert top_3 == [('trump', 5), ('president', 5), ('russian', 4)]\n\n\n# show the 3 most common words as table\nfd.tabulate(3)\n\n    trump president   russian \n        5         5         4 \n\n\n\n\nPlot common words\n\n# Obtain top 10 words\ntop_10 = fd.most_common(10)\n\ntop_10\n\n[('trump', 5),\n ('president', 5),\n ('russian', 4),\n ('six', 3),\n ('britain', 3),\n ('source', 3),\n ('one', 3),\n ('student', 2),\n ('found', 2),\n ('prime', 2)]\n\n\n\n# make a pandas datframe from the dictionary\ndf_dist = pd.DataFrame({\"value\": dict(top_10)})\n\ndf_dist\n\n\n\n\n\n\n\n\nvalue\n\n\n\n\nbritain\n3\n\n\nfound\n2\n\n\none\n3\n\n\npresident\n5\n\n\nprime\n2\n\n\nrussian\n4\n\n\nsix\n3\n\n\nsource\n3\n\n\nstudent\n2\n\n\ntrump\n5\n\n\n\n\n\n\n\n\n# reset index to transform index to column\ndf_dist.reset_index(inplace=True)\n\ndf_dist\n\n\n\n\n\n\n\n\nindex\nvalue\n\n\n\n\n0\nbritain\n3\n\n\n1\nfound\n2\n\n\n2\none\n3\n\n\n3\npresident\n5\n\n\n4\nprime\n2\n\n\n5\nrussian\n4\n\n\n6\nsix\n3\n\n\n7\nsource\n3\n\n\n8\nstudent\n2\n\n\n9\ntrump\n5\n\n\n\n\n\n\n\n\nimport altair as alt\n\nalt.Chart(df_dist).mark_bar().encode(\n    x=alt.X(\"value\"),\n    y=alt.Y(\"index\", sort=\"-x\")\n)\n\n\n\n\n\n\n\n\nSearch specific words\n\n# Show frequency of a specific word\nfd[\"trump\"]\n\n5"
  },
  {
    "objectID": "code/2_sentiment.html",
    "href": "code/2_sentiment.html",
    "title": "Sentiment Analysis with NLTK",
    "section": "",
    "text": "We need the following modules:\n\nNLTK\nPandas\nAltair\n\n\nimport nltk\n\n# we suppress some unimportant warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)"
  },
  {
    "objectID": "code/2_sentiment.html#python-setup",
    "href": "code/2_sentiment.html#python-setup",
    "title": "Sentiment Analysis with NLTK",
    "section": "",
    "text": "We need the following modules:\n\nNLTK\nPandas\nAltair\n\n\nimport nltk\n\n# we suppress some unimportant warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)"
  },
  {
    "objectID": "code/2_sentiment.html#data",
    "href": "code/2_sentiment.html#data",
    "title": "Sentiment Analysis with NLTK",
    "section": "Data",
    "text": "Data\n\nData import\n\nimport pandas as pd\n\n# Import some prepared twitter data from cnn breaking news\ndf = pd.read_csv(\"https://raw.githubusercontent.com/kirenz/datasets/master/sentiment-cnn.csv\")\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\ntext_token_s\ntext_si\ntext_sil\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n['the', 'body', 'of', 'missing', 'princeton', ...\n['body', 'missing', 'princeton', 'university',...\nbody missing princeton university student misr...\nbody missing princeton university student misr...\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\nprime minister liz truss quits disastrous six ...\nprime minister liz truss quits disastrous six ...\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n['trump', 'weighs', 'letting', 'federal', 'age...\n['trump', 'weighs', 'letting', 'federal', 'age...\ntrump weighs letting federal agents return mar...\ntrump weighs letting federal agents return mar...\n\n\n\n\n\n\n\n\n\nData corrections\n\ndf['created_at'] = pd.to_datetime(df['created_at'])\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 22 entries, 0 to 21\nData columns (total 6 columns):\n #   Column        Non-Null Count  Dtype              \n---  ------        --------------  -----              \n 0   text          22 non-null     object             \n 1   created_at    22 non-null     datetime64[ns, UTC]\n 2   text_token    22 non-null     object             \n 3   text_token_s  22 non-null     object             \n 4   text_si       22 non-null     object             \n 5   text_sil      22 non-null     object             \ndtypes: datetime64[ns, UTC](1), object(5)\nmemory usage: 1.2+ KB"
  },
  {
    "objectID": "code/2_sentiment.html#analysis",
    "href": "code/2_sentiment.html#analysis",
    "title": "Sentiment Analysis with NLTK",
    "section": "Analysis",
    "text": "Analysis\n\nVADER lexicon\n\nNLTK provides a simple rule-based model for general sentiment analysis called VADER, which stands for ‚ÄúValence Aware Dictionary and Sentiment Reasoner‚Äù (Hutto & Gilbert, 2014).\n\n\nnltk.download('vader_lexicon')\n\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/jankirenz/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n\n\nTrue\n\n\n\n\nSentiment Intensity Analyzer\n\nInitialize an object of SentimentIntensityAnalyzer with name ‚Äúanalyzer‚Äù:\n\n\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\nanalyzer = SentimentIntensityAnalyzer()\n\n\n\nPolarity scores\n\nUse the polarity_scores method:\n\n\ndf['polarity'] = df['text_sil'].apply(lambda x: analyzer.polarity_scores(x))\n\n\ndf.head(3)\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\ntext_token_s\ntext_si\ntext_sil\npolarity\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n['the', 'body', 'of', 'missing', 'princeton', ...\n['body', 'missing', 'princeton', 'university',...\nbody missing princeton university student misr...\nbody missing princeton university student misr...\n{'neg': 0.216, 'neu': 0.784, 'pos': 0.0, 'comp...\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\nprime minister liz truss quits disastrous six ...\nprime minister liz truss quits disastrous six ...\n{'neg': 0.206, 'neu': 0.794, 'pos': 0.0, 'comp...\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n['trump', 'weighs', 'letting', 'federal', 'age...\n['trump', 'weighs', 'letting', 'federal', 'age...\ntrump weighs letting federal agents return mar...\ntrump weighs letting federal agents return mar...\n{'neg': 0.0, 'neu': 0.86, 'pos': 0.14, 'compou...\n\n\n\n\n\n\n\n\n\nTransform data\n\n# Change data structure (we unnest the column polarity and add new columns)\ndf = pd.concat([df.drop(['polarity'], axis=1), df['polarity'].apply(pd.Series)], axis=1)\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\ntext_token_s\ntext_si\ntext_sil\nneg\nneu\npos\ncompound\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n['the', 'body', 'of', 'missing', 'princeton', ...\n['body', 'missing', 'princeton', 'university',...\nbody missing princeton university student misr...\nbody missing princeton university student misr...\n0.216\n0.784\n0.00\n-0.2960\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\nprime minister liz truss quits disastrous six ...\nprime minister liz truss quits disastrous six ...\n0.206\n0.794\n0.00\n-0.5994\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n['trump', 'weighs', 'letting', 'federal', 'age...\n['trump', 'weighs', 'letting', 'federal', 'age...\ntrump weighs letting federal agents return mar...\ntrump weighs letting federal agents return mar...\n0.000\n0.860\n0.14\n0.3818\n\n\n3\nbritain's home secretary suella braverman quit...\n2022-10-19 16:17:29+00:00\n['britain', 's', 'home', 'secretary', 'suella'...\n['britain', 'home', 'secretary', 'suella', 'br...\nbritain home secretary suella braverman quits ...\nbritain home secretary suella braverman quits ...\n0.152\n0.848\n0.00\n-0.3612\n\n\n4\nrussian president vladimir putin signs a decre...\n2022-10-19 12:02:15+00:00\n['russian', 'president', 'vladimir', 'putin', ...\n['russian', 'president', 'vladimir', 'putin', ...\nrussian president vladimir putin signs decree ...\nrussian president vladimir putin signs decree ...\n0.000\n1.000\n0.00\n0.0000\n\n\n\n\n\n\n\nCreate new variable called sentiment which contains the entries ‚Äúneutral,‚Äù ‚Äúpositive‚Äù or ‚Äúnegative‚Äù (depending on the compound score).\nHint:\n\ndf['___'] = df['___'].___(___ x: '___' if ___ &gt;___ else '___' if ___ else '___')\n\n\nName the new variable sentiment\nUse variable compound as basis\napply a lambda function to each row.\nThe lambda function should write a name in a cell:\n\n‚Äòpositive‚Äô if x&gt;0\n‚Äòneutral‚Äô if x==0\n‚Äònegative‚Äô for all other cases (else)\n\n\n\n### BEGIN SOLUTION\ndf['sentiment'] = df['compound'].apply(lambda x: 'positive' if x &gt;0 else 'neutral' if x==0 else 'negative')\n### END SOLUTION\n\n\n# check your code\nassert df.iloc[0, 10] == 'negative'\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\ntext_token_s\ntext_si\ntext_sil\nneg\nneu\npos\ncompound\nsentiment\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n['the', 'body', 'of', 'missing', 'princeton', ...\n['body', 'missing', 'princeton', 'university',...\nbody missing princeton university student misr...\nbody missing princeton university student misr...\n0.216\n0.784\n0.00\n-0.2960\nnegative\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\nprime minister liz truss quits disastrous six ...\nprime minister liz truss quits disastrous six ...\n0.206\n0.794\n0.00\n-0.5994\nnegative\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n['trump', 'weighs', 'letting', 'federal', 'age...\n['trump', 'weighs', 'letting', 'federal', 'age...\ntrump weighs letting federal agents return mar...\ntrump weighs letting federal agents return mar...\n0.000\n0.860\n0.14\n0.3818\npositive\n\n\n3\nbritain's home secretary suella braverman quit...\n2022-10-19 16:17:29+00:00\n['britain', 's', 'home', 'secretary', 'suella'...\n['britain', 'home', 'secretary', 'suella', 'br...\nbritain home secretary suella braverman quits ...\nbritain home secretary suella braverman quits ...\n0.152\n0.848\n0.00\n-0.3612\nnegative\n\n\n4\nrussian president vladimir putin signs a decre...\n2022-10-19 12:02:15+00:00\n['russian', 'president', 'vladimir', 'putin', ...\n['russian', 'president', 'vladimir', 'putin', ...\nrussian president vladimir putin signs decree ...\nrussian president vladimir putin signs decree ...\n0.000\n1.000\n0.00\n0.0000\nneutral\n\n\n\n\n\n\n\n\n\nMax and min sentiment\n\n# Tweet with highest positive sentiment\ndf[['text', 'compound', 'neg', 'neu', 'pos', 'sentiment']].loc[df['compound'].idxmax()]\n\ntext         bruce sutter, a cy young award-winning relief ...\ncompound                                                0.8834\nneg                                                      0.126\nneu                                                      0.386\npos                                                      0.488\nsentiment                                             positive\nName: 16, dtype: object\n\n\n\n# Tweet with highest negative sentiment \n# ...seems to be a case of wrong classification because of the word \"deficit\"\ndf[['text', 'compound', 'neg', 'neu', 'pos', 'sentiment']].loc[df['compound'].idxmin()]\n\ntext         jury finds paul flores guilty of first-degree ...\ncompound                                               -0.9531\nneg                                                       0.58\nneu                                                      0.337\npos                                                      0.083\nsentiment                                             negative\nName: 6, dtype: object\n\n\n\n\nVisualize data\n\nimport altair as alt\n\n# create data to change colors in Altair plot\ndomain = ['neutral', 'positive', 'negative']\nrange_=['#b2d8d8',\"#008080\", '#db3d13']\n\n\nalt.Chart(df).mark_bar().encode(\n    x=alt.X('count()', title=None),\n    y=alt.Y('sentiment', sort=\"-x\"),\n    color= alt.Color('sentiment', legend=None, scale=alt.Scale(domain=domain, range=range_))\n).properties(\n    title=\"Sentiment analysis\",\n    width=400,\n    height=150,\n)\n\n\n\n\n\n\n\n# Function to add date variables to DataFrame.\ndef add_date_info(df):\n  df['created_at'] = pd.to_datetime(df['created_at'], unit='ns')\n  df['Year'] = pd.DatetimeIndex(df['created_at']).year\n  df['Month'] = pd.DatetimeIndex(df['created_at']).month\n  df['Day'] = pd.DatetimeIndex(df['created_at']).day\n  df['DOY'] = pd.DatetimeIndex(df['created_at']).dayofyear\n  df['Date'] = pd.DatetimeIndex(df['created_at']).date\n  return df\n\n\nadd_date_info(df)\n\n\n\n\n\n\n\n\ntext\ncreated_at\ntext_token\ntext_token_s\ntext_si\ntext_sil\nneg\nneu\npos\ncompound\nsentiment\nYear\nMonth\nDay\nDOY\nDate\n\n\n\n\n0\nthe body of missing princeton university stude...\n2022-10-20 19:58:17+00:00\n['the', 'body', 'of', 'missing', 'princeton', ...\n['body', 'missing', 'princeton', 'university',...\nbody missing princeton university student misr...\nbody missing princeton university student misr...\n0.216\n0.784\n0.000\n-0.2960\nnegative\n2022\n10\n20\n293\n2022-10-20\n\n\n1\nuk prime minister liz truss quits after a disa...\n2022-10-20 12:37:10+00:00\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\n['uk', 'prime', 'minister', 'liz', 'truss', 'q...\nprime minister liz truss quits disastrous six ...\nprime minister liz truss quits disastrous six ...\n0.206\n0.794\n0.000\n-0.5994\nnegative\n2022\n10\n20\n293\n2022-10-20\n\n\n2\ntrump weighs letting federal agents return to ...\n2022-10-19 23:03:37+00:00\n['trump', 'weighs', 'letting', 'federal', 'age...\n['trump', 'weighs', 'letting', 'federal', 'age...\ntrump weighs letting federal agents return mar...\ntrump weighs letting federal agents return mar...\n0.000\n0.860\n0.140\n0.3818\npositive\n2022\n10\n19\n292\n2022-10-19\n\n\n3\nbritain's home secretary suella braverman quit...\n2022-10-19 16:17:29+00:00\n['britain', 's', 'home', 'secretary', 'suella'...\n['britain', 'home', 'secretary', 'suella', 'br...\nbritain home secretary suella braverman quits ...\nbritain home secretary suella braverman quits ...\n0.152\n0.848\n0.000\n-0.3612\nnegative\n2022\n10\n19\n292\n2022-10-19\n\n\n4\nrussian president vladimir putin signs a decre...\n2022-10-19 12:02:15+00:00\n['russian', 'president', 'vladimir', 'putin', ...\n['russian', 'president', 'vladimir', 'putin', ...\nrussian president vladimir putin signs decree ...\nrussian president vladimir putin signs decree ...\n0.000\n1.000\n0.000\n0.0000\nneutral\n2022\n10\n19\n292\n2022-10-19\n\n\n5\nrising food and housing costs drove uk inflati...\n2022-10-19 09:04:45+00:00\n['rising', 'food', 'and', 'housing', 'costs', ...\n['rising', 'food', 'housing', 'costs', 'drove'...\nrising food housing costs drove inflation back...\nrising food housing costs drove inflation back...\n0.000\n1.000\n0.000\n0.0000\nneutral\n2022\n10\n19\n292\n2022-10-19\n\n\n6\njury finds paul flores guilty of first-degree ...\n2022-10-18 21:35:05+00:00\n['jury', 'finds', 'paul', 'flores', 'guilty', ...\n['jury', 'finds', 'paul', 'flores', 'guilty', ...\njury finds paul flores guilty first degree mur...\njury finds paul flores guilty first degree mur...\n0.580\n0.337\n0.083\n-0.9531\nnegative\n2022\n10\n18\n291\n2022-10-18\n\n\n7\nrussian expat who was the main source for infa...\n2022-10-18 20:29:03+00:00\n['russian', 'expat', 'who', 'was', 'the', 'mai...\n['russian', 'expat', 'main', 'source', 'infamo...\nrussian expat main source infamous trump dossi...\nrussian expat main source infamous trump dossi...\n0.364\n0.445\n0.190\n-0.6486\nnegative\n2022\n10\n18\n291\n2022-10-18\n\n\n8\na pilot and passenger are dead after a plane c...\n2022-10-18 16:00:21+00:00\n['a', 'pilot', 'and', 'passenger', 'are', 'dea...\n['pilot', 'passenger', 'dead', 'plane', 'crash...\npilot passenger dead plane crashed car dealers...\npilot passenger dead plane crashed car dealers...\n0.318\n0.682\n0.000\n-0.7906\nnegative\n2022\n10\n18\n291\n2022-10-18\n\n\n9\nukraine's president zelensky says 30% of the c...\n2022-10-18 10:33:29+00:00\n['ukraine', 's', 'president', 'zelensky', 'say...\n['ukraine', 'president', 'zelensky', 'says', '...\nukraine president zelensky says country power ...\nukraine president zelensky says country power ...\n0.357\n0.643\n0.000\n-0.7269\nnegative\n2022\n10\n18\n291\n2022-10-18\n\n\n10\npresident biden announces the formal launch of...\n2022-10-17 19:27:45+00:00\n['president', 'biden', 'announces', 'the', 'fo...\n['president', 'biden', 'announces', 'formal', ...\npresident biden announces formal launch studen...\npresident biden announces formal launch studen...\n0.000\n0.826\n0.174\n0.2732\npositive\n2022\n10\n17\n290\n2022-10-17\n\n\n11\na russian fighter jet has crashed into a resid...\n2022-10-17 17:27:13+00:00\n['a', 'russian', 'fighter', 'jet', 'has', 'cra...\n['russian', 'fighter', 'jet', 'crashed', 'resi...\nrussian fighter jet crashed residential buildi...\nrussian fighter jet crashed residential buildi...\n0.000\n0.882\n0.118\n0.1531\npositive\n2022\n10\n17\n290\n2022-10-17\n\n\n12\nformer president donald trump's company charge...\n2022-10-17 16:31:30+00:00\n['former', 'president', 'donald', 'trump', 's'...\n['former', 'president', 'donald', 'trump', 'co...\nformer president donald trump company charged ...\nformer president donald trump company charged ...\n0.184\n0.816\n0.000\n-0.5426\nnegative\n2022\n10\n17\n290\n2022-10-17\n\n\n13\nsteve bannon sentencing recommendation seeks s...\n2022-10-17 13:08:39+00:00\n['steve', 'bannon', 'sentencing', 'recommendat...\n['steve', 'bannon', 'sentencing', 'recommendat...\nsteve bannon sentencing recommendation seeks s...\nsteve bannon sentencing recommendation seeks s...\n0.401\n0.599\n0.000\n-0.8271\nnegative\n2022\n10\n17\n290\n2022-10-17\n\n\n14\nblasts were heard in the ukrainian capital as ...\n2022-10-17 05:12:01+00:00\n['blasts', 'were', 'heard', 'in', 'the', 'ukra...\n['blasts', 'heard', 'ukrainian', 'capital', 'r...\nblasts heard ukrainian capital result apparent...\nblasts heard ukrainian capital result apparent...\n0.152\n0.848\n0.000\n-0.3612\nnegative\n2022\n10\n17\n290\n2022-10-17\n\n\n15\nauthorities in central california have arreste...\n2022-10-15 23:48:28+00:00\n['authorities', 'in', 'central', 'california',...\n['authorities', 'central', 'california', 'arre...\nauthorities central california arrested man co...\nauthorities central california arrested man co...\n0.409\n0.591\n0.000\n-0.8225\nnegative\n2022\n10\n15\n288\n2022-10-15\n\n\n16\nbruce sutter, a cy young award-winning relief ...\n2022-10-14 20:06:13+00:00\n['bruce', 'sutter', 'a', 'cy', 'young', 'award...\n['bruce', 'sutter', 'cy', 'young', 'award', 'w...\nbruce sutter young award winning relief pitche...\nbruce sutter young award winning relief pitche...\n0.126\n0.386\n0.488\n0.8834\npositive\n2022\n10\n14\n287\n2022-10-14\n\n\n17\njudge throws out one of five charges against i...\n2022-10-14 19:39:52+00:00\n['judge', 'throws', 'out', 'one', 'of', 'five'...\n['judge', 'throws', 'one', 'five', 'charges', ...\njudge throws one five charges igor danchenko m...\njudge throws one five charges igor danchenko m...\n0.096\n0.780\n0.124\n0.1531\npositive\n2022\n10\n14\n287\n2022-10-14\n\n\n18\nrobbie coltrane, the actor who brought to life...\n2022-10-14 17:30:19+00:00\n['robbie', 'coltrane', 'the', 'actor', 'who', ...\n['robbie', 'coltrane', 'actor', 'brought', 'li...\nrobbie coltrane actor brought life lovable gam...\nrobbie coltrane actor brought life lovable gam...\n0.153\n0.678\n0.169\n0.1027\npositive\n2022\n10\n14\n287\n2022-10-14\n\n\n19\nformer president trump has not said whether he...\n2022-10-14 14:52:35+00:00\n['former', 'president', 'trump', 'has', 'not',...\n['former', 'president', 'trump', 'said', 'whet...\nformer president trump said whether comply sub...\nformer president trump said whether comply sub...\n0.000\n1.000\n0.000\n0.0000\nneutral\n2022\n10\n14\n287\n2022-10-14\n\n\n20\nkwasi kwarteng has been fired as britain's cha...\n2022-10-14 11:44:29+00:00\n['kwasi', 'kwarteng', 'has', 'been', 'fired', ...\n['kwasi', 'kwarteng', 'fired', 'britain', 'cha...\nkwasi kwarteng fired britain chancellor weeks ...\nkwasi kwarteng fired britain chancellor weeks ...\n0.175\n0.825\n0.000\n-0.5574\nnegative\n2022\n10\n14\n287\n2022-10-14\n\n\n21\nkroger announces it's merging with albertsons ...\n2022-10-14 11:40:16+00:00\n['kroger', 'announces', 'it', 's', 'merging', ...\n['kroger', 'announces', 'merging', 'albertsons...\nkroger announces merging albertsons billion de...\nkroger announces merging albertsons billion de...\n0.000\n0.845\n0.155\n0.2960\npositive\n2022\n10\n14\n287\n2022-10-14\n\n\n\n\n\n\n\n\n# change format\ndf['Date'] = pd.to_datetime(df['Date'])\n\n\nalt.Chart(df).mark_area().encode(\n   x=alt.X('Date', axis=alt.Axis(format='%e.%-m.')),\n   y=alt.Y('count(sentiment)'),\n   color=alt.Color('sentiment', scale=alt.Scale(domain=domain, range=range_))\n)\n\n\n\n\n\n\n\nalt.Chart(df).mark_boxplot().encode(\n    x=alt.X('sentiment'),\n    y=alt.Y('compound'),\n    color=alt.Color('sentiment', scale=alt.Scale(domain=domain, range=range_))\n).properties(\n    width=200,\n    height=200\n)\n\n\n\n\n\n\nLiterature:\nHutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
  },
  {
    "objectID": "requirements.html",
    "href": "requirements.html",
    "title": "Requirements",
    "section": "",
    "text": "To start this lab, you‚Äôll need the following environments:\n\n\n\n\n\n\nImportant\n\n\n\nVisit the ‚ÄúProgramming Toolkit-webpage‚Äù to learn how to meet all requirements.\n\n\n\nSQL: MySQL, MySQL Workbench and a database called db_data\nPython: Anaconda, Anaconda Environment lab and Visual Studio Code\nEnvironment: A folder on your machine called competitive and an environment file with your MySQL password"
  },
  {
    "objectID": "slide.html",
    "href": "slide.html",
    "title": "Slides",
    "section": "",
    "text": "The following tutorials are mainly based on ‚Äú‚Äù provided by\nTxt"
  },
  {
    "objectID": "slide.html#txt",
    "href": "slide.html#txt",
    "title": "Slides",
    "section": "1 Txt",
    "text": "1 Txt\nIn this tutorial, you‚Äôll learn:\n\n\n\n\n\n\n\nüñ•Ô∏è Presentation\nüíª Jupyter Notebook\n\n\n\n\nüíª Accept the invitation to application exercise Nr. 3 in Moodle: üíª textmining"
  }
]